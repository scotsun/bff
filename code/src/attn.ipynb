{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimental_utils.load_data import generate_yearly_data\n",
    "from experimental_utils.load_vocab import load_joint_vocab\n",
    "from train_clf_asd import get_modality_config\n",
    "from core.data_utils import MODALITY_DATA_SELECT, SUPPRESS_MODALITY\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from core.data_utils import MultiModalCollate\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "from experimental_utils.track_model import select_model, parse_tags_from_filename \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODALITY_FLAGS = [\"all\"]\n",
    "TASK = \"binary\"\n",
    "MODALITY_CHECKPOINT = \"first_check\"\n",
    "\n",
    "MODALITY_CONFIG = get_modality_config(MODALITY_FLAGS)\n",
    "MODALITIES = [k for k, v in MODALITY_CONFIG.items() if v]\n",
    "N_MODALITY = len(MODALITIES)\n",
    "\n",
    "MIXING_MODULE = \"softmax-gating\"\n",
    "ZP_ONLY = False\n",
    "ADD_CONTRASTIVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERING_TAGS = {\n",
    "    \"modality_checkpoint\": MODALITY_CHECKPOINT,\n",
    "    \"mixing_approach\": MIXING_MODULE,\n",
    "    \"contrast\": ADD_CONTRASTIVE,\n",
    "    \"zp_only\": ZP_ONLY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:47<00:00,  1.47s/file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 19145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:00<00:00, 1671.60it/s]s]\n",
      "100%|██████████| 379/379 [00:00<00:00, 1692.99it/s] 2.64s/it]\n",
      "100%|██████████| 367/367 [00:00<00:00, 1631.60it/s] 2.90s/it]\n",
      "100%|██████████| 116/116 [00:00<00:00, 1659.09it/s] 3.06s/it]\n",
      "0it [00:00, ?it/s]0%|█████     | 4/8 [00:12<00:12,  3.07s/it]\n",
      "0it [00:00, ?it/s]2%|██████▎   | 5/8 [00:15<00:09,  3.09s/it]\n",
      "0it [00:00, ?it/s]5%|███████▌  | 6/8 [00:18<00:06,  3.11s/it]\n",
      "0it [00:00, ?it/s]8%|████████▊ | 7/8 [00:22<00:03,  3.40s/it]\n",
      "preparing test: 100%|██████████| 8/8 [00:26<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "EMBEDDING_DIM = 256\n",
    "\n",
    "# train_cohort = pd.read_csv(\"../../data/outcome/train_asd.csv\", dtype={\"PATID\": str})\n",
    "reference_cohort = pd.read_csv(\"../../data/outcome/test_asd.csv\", dtype={\"PATID\": str})\n",
    "test_cohort = pd.read_csv(\"../../data/rAOM/test_raom.csv\", dtype={\"PATID\": str})\n",
    "\n",
    "\n",
    "_, transform = load_joint_vocab(reference_cohort)\n",
    "# embeddings = load_joint_embeddings(vocab, EMBEDDING_DIM, DEVICE)\n",
    "\n",
    "test_dataset_list = [\n",
    "    generate_yearly_data(\n",
    "        'raom', i, test_cohort, transform, MODALITY_CONFIG, complete_case=False\n",
    "    )\n",
    "    for i in tqdm(range(2015, 2023), desc=\"preparing test\")\n",
    "]\n",
    "test_dataset = ConcatDataset(test_dataset_list)\n",
    "collate_fn = MultiModalCollate(n_modality=N_MODALITY, survival=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "event = batch[\"event\"].float().to(DEVICE)\n",
    "time = batch[\"time\"].float().to(DEVICE)\n",
    "masks = batch[\"mask\"].to(DEVICE)\n",
    "inputs = batch[\"inputs\"].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = [f for f in os.listdir(\"../../model_checkpoint/asd-archive\") if f\"all_None_{MIXING_MODULE}\" in f and f.endswith(\"pth\")]\n",
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_869.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"../../model_checkpoint/asd/{name}\", map_location=DEVICE)\n",
    "# model = torch.load(f\"../../model_checkpoint/asd/joint_survival_all_None_self-attention_570.pth\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model(\n",
    "    inputs=inputs,\n",
    "    masks=masks,\n",
    ")[-1]\n",
    "w = w.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[baby_birth, baby_dev, mom_birth, mom_prenatal] -> [mom_prenatal, mom_birth, baby_birth, baby_dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self-gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = int(torch.randint(size=(1,), low=0, high=w.shape[0]))\n",
    "# i = 89\n",
    "i = 152\n",
    "print(i, event[i].item(), time[i])\n",
    "print(masks[i][[3,2,0,1]])\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(w[i][[3,2,0,1],:], annot=False, cmap=\"viridis\", cbar=True, fmt='.2f')\n",
    "plt.xticks([])\n",
    "plt.yticks(\n",
    "    ticks=[0.5, 1.5, 2.5, 3.5], \n",
    "    labels=[\n",
    "        \"$m_{\\\\text{prenatal}}$\", \"$m_{\\\\text{birth}}^{\\\\text{mom}}$\",\n",
    "        \"$m_{\\\\text{birth}}^{\\\\text{baby}}$\", \"$m_{\\\\text{developmental}}$\"\n",
    "    ], \n",
    "    rotation=0\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = int(torch.randint(size=(1,), low=0, high=w.shape[0]))\n",
    "# i = 89\n",
    "i = 152\n",
    "print(i, event[i].item(), time[i])\n",
    "print(masks[i][[3,2,0,1]])\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(w[i][[3,2,0,1]][:,[3,2,0,1]], annot=False, cmap=\"viridis\", cbar=True, fmt='.2f')\n",
    "plt.xticks(\n",
    "    ticks=[0.5, 1.5, 2.5, 3.5], \n",
    "    labels=[\n",
    "        \"$m_{\\\\text{prenatal}}$\", \"$m_{\\\\text{birth}}^{\\\\text{mom}}$\",\n",
    "        \"$m_{\\\\text{birth}}^{\\\\text{baby}}$\", \"$m_{\\\\text{developmental}}$\"\n",
    "    ], \n",
    "    rotation=0\n",
    ")\n",
    "plt.yticks(\n",
    "    ticks=[0.5, 1.5, 2.5, 3.5], \n",
    "    labels=[\n",
    "        \"$m_{\\\\text{prenatal}}$\", \"$m_{\\\\text{birth}}^{\\\\text{mom}}$\",\n",
    "        \"$m_{\\\\text{birth}}^{\\\\text{baby}}$\", \"$m_{\\\\text{developmental}}$\"\n",
    "    ], \n",
    "    rotation=0\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_869.pth\"\n",
    "# name = \"joint_survival_all_first_check_softmax-gating_157.pth\"\n",
    "model = torch.load(f\"../../model_checkpoint/asd-archive/{name}\", map_location=DEVICE)\n",
    "\n",
    "def forward_func(inputs, masks):\n",
    "    return model(inputs, masks)[0]\n",
    "lig = LayerIntegratedGradients(forward_func, model.embedding_module)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "event = batch[\"event\"].float().to(DEVICE)\n",
    "time = batch[\"time\"].float().to(DEVICE)\n",
    "masks = batch[\"mask\"].to(DEVICE)\n",
    "inputs = batch[\"inputs\"].to(DEVICE)\n",
    "\n",
    "attr, delta = lig.attribute(\n",
    "    inputs=inputs,\n",
    "    target=8,\n",
    "    additional_forward_args=(masks,),\n",
    "    n_steps=50,\n",
    "    internal_batch_size=128,\n",
    "    return_convergence_delta=True\n",
    ")\n",
    "attr = -attr[:, [3,2,0,1], :, :]\n",
    "masks = masks[:, [3,2,0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modality level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joint_binary_all_first_check_softmax-gating_contrast_zpOnly_232.pth',\n",
       " 'joint_binary_all_first_check_softmax-gating_contrast_zpOnly_260.pth',\n",
       " 'joint_binary_all_first_check_softmax-gating_contrast_zpOnly_143.pth',\n",
       " 'joint_binary_all_first_check_softmax-gating_contrast_zpOnly_971.pth',\n",
       " 'joint_binary_all_first_check_softmax-gating_contrast_zpOnly_262.pth']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_names = [\n",
    "#     \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_869.pth\",\n",
    "#     \"joint_survival_all_first_check_softmax-gating_contrast_924.pth\",\n",
    "#     \"joint_survival_all_first_check_softmax-gating_157.pth\",\n",
    "#     \"joint_survival_all_mid_check_softmax-gating_contrast_zpOnly_241.pth\",\n",
    "#     \"joint_survival_all_mid_check_softmax-gating_contrast_859.pth\",\n",
    "#     \"joint_survival_all_mid_check_softmax-gating_418.pth\",\n",
    "#     \"joint_survival_all_final_check_softmax-gating_contrast_zpOnly_810.pth\",\n",
    "#     \"joint_survival_all_final_check_softmax-gating_contrast_134.pth\",\n",
    "#     \"joint_survival_all_final_check_softmax-gating.pth\"\n",
    "# ]\n",
    "\n",
    "filtering_tags = {\n",
    "    \"modality_checkpoint\": \"first_check\",\n",
    "    \"mixing_approach\": \"softmax-gating\",\n",
    "    \"contrast\": True,\n",
    "    \"zp_only\": True\n",
    "}\n",
    "\n",
    "model_names = select_model(\n",
    "    root=\"../../model_checkpoint/raom-archive\",\n",
    "    filtering_tags=filtering_tags\n",
    ")\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_binary_all_first_check_softmax-gating_contrast_zpOnly_232.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2280, 0.3040, 0.2890, 0.1780], device='cuda:0')\n",
      "\n",
      "joint_binary_all_first_check_softmax-gating_contrast_zpOnly_260.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2410, 0.3160, 0.2470, 0.1960], device='cuda:0')\n",
      "\n",
      "joint_binary_all_first_check_softmax-gating_contrast_zpOnly_143.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2240, 0.3060, 0.2550, 0.2150], device='cuda:0')\n",
      "\n",
      "joint_binary_all_first_check_softmax-gating_contrast_zpOnly_971.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2590, 0.2960, 0.2440, 0.2010], device='cuda:0')\n",
      "\n",
      "joint_binary_all_first_check_softmax-gating_contrast_zpOnly_262.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2310, 0.2990, 0.2590, 0.2120], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "importance_list = []\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    model = torch.load(f\"../../model_checkpoint/raom-archive/{name}\", map_location=DEVICE)\n",
    "    def forward_func(inputs, masks):\n",
    "        return model(inputs, masks)[0]\n",
    "    lig = LayerIntegratedGradients(forward_func, model.embedding_module)\n",
    "\n",
    "    importance = torch.zeros((4,)).to(DEVICE)\n",
    "    for batch in tqdm(test_loader):\n",
    "        masks = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        if not masks.all(dim=1).any().item(): # if all samples in the batch do not have complete obs\n",
    "            continue\n",
    "\n",
    "        inputs = batch[\"inputs\"].to(DEVICE)\n",
    "        attr, delta = lig.attribute(\n",
    "            inputs=inputs,\n",
    "            target=0,\n",
    "            additional_forward_args=(masks,),\n",
    "            n_steps=50,\n",
    "            internal_batch_size=128,\n",
    "            return_convergence_delta=True\n",
    "        )\n",
    "        attr = attr[:, [3,2,0,1], :, :]\n",
    "        masks = masks[:, [3,2,0,1]]\n",
    "        attr = attr[masks.all(dim=1)].abs().sum(dim=-1) #(B, 4, L)\n",
    "\n",
    "        # min-max norm\n",
    "        attr = (attr - attr.min()) / (attr.max() - attr.min())\n",
    "\n",
    "        # clip outliers at 99th percentile\n",
    "        # attr = torch.clamp(attr, max=torch.quantile(attr, 0.99))\n",
    "\n",
    "        a = attr.sum(dim=-1)\n",
    "        importance += (a / a.sum(dim=-1, keepdim=True)).mean(dim=0) / len(test_loader)\n",
    "    importance_list.append(importance)\n",
    "        \n",
    "    print(importance.round(decimals=3))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23660431802272797, 0.3042547106742859, 0.2585369944572449, 0.20060400664806366]\n",
      "[0.01402726024389267, 0.007799405604600906, 0.01794830895960331, 0.014584501273930073]\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack(importance_list).mean(dim=0).cpu().tolist())\n",
    "print(torch.stack(importance_list).std(dim=0).cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"|\".join([filtering_tags[\"modality_checkpoint\"], filtering_tags[\"mixing_approach\"]])\n",
    "if filtering_tags[\"contrast\"]:\n",
    "    m += \"|contrast\"\n",
    "if filtering_tags[\"zp_only\"]:\n",
    "    m += \"|zpOnly\"\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result[m] = {\n",
    "    'mean': torch.stack(importance_list).mean(dim=0).cpu().tolist(),\n",
    "    'std': torch.stack(importance_list).std(dim=0).cpu().tolist()\n",
    "}\n",
    "with open(\"../../modality_importance/test.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sctrach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_norm = torch.norm(attr.sum(dim=-1), dim=-1)\n",
    "mod_norm = mod_norm * (mod_norm != 0) + torch.ones_like(mod_norm) * (mod_norm == 0)\n",
    "attr.sum(dim=-1) / mod_norm[:,:,None]\n",
    "# shape (batch_size, 4, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = attr.sum(dim=-1) #/ mod_norm[:,:,None]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(dim=-1)[event == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(dim=-1)[event == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict\n",
    "\n",
    "def parallel_aggregate_joblib(inputs, attrs, n_jobs=-1):\n",
    "    def process_batch(batch):\n",
    "        local_dict = defaultdict(list)\n",
    "        for token, attr in batch:\n",
    "            local_dict[int(token)].append(float(attr))\n",
    "        return dict(local_dict)\n",
    "    \n",
    "    # Create batches\n",
    "    batch_size = len(inputs) // (n_jobs if n_jobs > 0 else 4)\n",
    "    batches = [list(zip(inputs[i:i+batch_size], attrs[i:i+batch_size])) \n",
    "               for i in range(0, len(inputs), batch_size)]\n",
    "    \n",
    "    # Process in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_batch)(batch) for batch in batches\n",
    "    )\n",
    "    \n",
    "    # Merge results\n",
    "    final_dict = defaultdict(list)\n",
    "    for result in results:\n",
    "        for key, values in result.items():\n",
    "            final_dict[key].extend(values)\n",
    "    \n",
    "    return dict(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions_across_samples(explainer, dataloader, device):\n",
    "    \"\"\"\n",
    "    Summarize attribution scores across samples for each token.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each unique token to the mean attribution score across samples.\n",
    "    \"\"\"\n",
    "    token_to_attributions = dict()\n",
    "    for batch in tqdm(dataloader):\n",
    "        masks = batch[\"mask\"].to(device)\n",
    "        inputs = batch[\"inputs\"].to(device)\n",
    "        attr, delta = explainer.attribute(\n",
    "            inputs=inputs,\n",
    "            target=8,\n",
    "            additional_forward_args=(masks,),\n",
    "            n_steps=50,\n",
    "            internal_batch_size=128,\n",
    "            return_convergence_delta=True\n",
    "        )\n",
    "        attr = -attr.sum(dim=-1) # negate as the anchored target is \"censoring\"\n",
    "        # mod_norm = torch.norm(attr.sum(dim=-1), dim=-1)\n",
    "        # mod_norm = mod_norm * (mod_norm != 0) + torch.ones_like(mod_norm) * (mod_norm == 0)\n",
    "        # attr = attr / mod_norm[:,:,None]\n",
    "        if float(delta.max()) > 0.05:\n",
    "            raise RuntimeWarning(\"convergence warning: large delta\")\n",
    "\n",
    "        inputs = inputs.flatten()\n",
    "        attr = attr.flatten()\n",
    "        \n",
    "\n",
    "        # Aggregate attributions by token\n",
    "        unique_tokens, inv_idx = torch.unique(inputs, return_inverse=True)\n",
    "        for i, token in enumerate(unique_tokens):\n",
    "            if int(token) not in token_to_attributions:\n",
    "                token_to_attributions[int(token)] = []\n",
    "            token_to_attributions[int(token)].extend(attr[inv_idx == i].tolist())\n",
    "\n",
    "        # for token, attr in zip(inputs, attr):\n",
    "        #     if int(token) not in token_to_attributions:\n",
    "        #         token_to_attributions[int(token)] = []\n",
    "        #     token_to_attributions[int(token)].append(float(attr))\n",
    "        \n",
    "\n",
    "    return token_to_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "model_names = [\n",
    "    \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_772\",\n",
    "    \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_555\",\n",
    "    \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_899\",\n",
    "    \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_823\",\n",
    "    \"joint_survival_all_first_check_softmax-gating_contrast_zpOnly_274\"\n",
    "]\n",
    "\n",
    "attr_dict_list = []\n",
    "for name in model_names:\n",
    "    model = torch.load(f\"../../model_checkpoint/asd-archive/{name}.pth\", map_location=DEVICE)\n",
    "    def forward_func(inputs, masks):\n",
    "        return model(inputs, masks)[0]\n",
    "    lig = LayerIntegratedGradients(forward_func, model.embedding_module)\n",
    "    attr_dict = summarize_attributions_across_samples(lig, test_loader, DEVICE)\n",
    "    attr_dict_list.append(attr_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = {token: 0 for token, _ in attr_dict.items()}\n",
    "for elem in attr_dict_list:\n",
    "    for token in elem.keys():\n",
    "        h[token] += torch.tensor(elem[token]).mean() / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_pos_tokens = dict(sorted(h.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "top10_neg_tokens = dict(sorted(h.items(), key=lambda x: x[1], reverse=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_pos_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_neg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top10_pos_tokens.keys())\n",
    "vocab.lookup_tokens(list(top10_pos_tokens.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top10_neg_tokens.keys())\n",
    "vocab.lookup_tokens(list(top10_neg_tokens.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
